import os
import pandas as pd
import re
import numpy as np

def find_and_replace(sentence, word, start_tag, end_tag):
    """
    Ensures that an <e2> tag cannot occur in <e1> tag
    """
    results = re.finditer(r"\b(" + word + r")\b", sentence)
    #results = re.finditer(word, sentence)
    results_valid = []
    e1_enclosed = re.search("<e1>.*<\/e1>", sentence)

    for m in results:
        if e1_enclosed is None:
            results_valid.append(m)
            break
        if e1_enclosed.start() < m.start() < e1_enclosed.end() or e1_enclosed.start() < m.end() < e1_enclosed.end():
            continue
        results_valid.append(m)
    start, end = results_valid[0].span()
    return sentence[:start] + start_tag + sentence[start:end] + end_tag + sentence[end:]


def convert_termframe(annotated_definitions_path, output_file):
    """
    Converts annotated TermFrame csv files (generated by webanno2csv tool) to the same format that SemEval dataset uses
    """
    f = open(output_file, "w", encoding="utf-8")

    count = 0
    skipped = 0

    for num in range(1, 50):
        print("Iteration", num)
        #if num == 2: continue

        def_elements = pd.read_csv(annotated_definitions_path + "defs-en-%s__DEF_ELEMENTS.csv" % str(num), encoding="utf-8")

        rel_rel_frame = pd.read_csv(annotated_definitions_path + "defs-en-%s__REL_REL_FRAME.csv" % str(num), encoding="utf-8")

        for i, row in def_elements.iterrows():

            # Get sentence, definiendum, and genus
            sentence = row["SENTENCE"]
            sentence_original = row["SENTENCE"]
            definiendum = row["DEFINIENDUM"]
            genus = row["GENUS"]
            try:
                index_definiendum = re.search(r"\b(" + definiendum + r")\b", sentence).start()
                index_genus = re.search(r"\b(" + genus + r")\b", sentence).start()
            except Exception as e:
                skipped += 1
                continue

            # Set first occuring definiendum/genus as e1 and other as e2
            if index_definiendum < index_genus:
                e1 = definiendum
                e2 = genus
            else:
                e1 = genus
                e2 = definiendum

            try:
                sentence = find_and_replace(sentence, e1, "<e1>", "</e1>")
                sentence = find_and_replace(sentence, e2, "<e2>", "</e2>")
            except Exception as e:
                skipped += 1
                continue

            # Find relation(s) for the sentence
            relation_num = 0
            relations = set()
            for j, row2 in rel_rel_frame.iterrows():
                rel_tok = row2["REL_TOK"]
                if pd.isna(rel_tok): continue
                if rel_tok.replace(" ", "") in sentence_original.replace(" ", ""):
                    if index_definiendum < index_genus: relations.add("%s(e1,e2)" % row2["REL_LABEL"])
                    else:
                        relations.add("%s(e2,e1)" % row2["REL_LABEL"])
                    relation_num += 1
            
            if relation_num == 0:
                skipped += 1
                continue

            f.write("%d\t%s\n" % (count, sentence))
            f.write(" ".join(relations))
            f.write("\nComment: \n\n")

            count += 1

    f.close()
    print("Skipped %d records" % skipped)


annotated_definitions_path = "../../data/Karst Annotated Definitions/AnnotatedDefinitions/EN/"
output_file = "AnnotatedDefinitions_EN.txt"

convert_termframe(annotated_definitions_path, output_file)
